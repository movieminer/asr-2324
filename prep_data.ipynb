{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import pylangacq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paths:\n",
    "  path = '/vol/tensusers3/thijsdejong/2324-asr'\n",
    "  transcriptions = f'{path}/datasets/addresso/test/transcription'\n",
    "  text_participants = f'{path}/datasets/addresso/test/text_participants'\n",
    "  text_both = f'{path}/datasets/addresso/test/text_both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_text(path, full_transcript=False):\n",
    "    chat = pylangacq.read_chat(path)\n",
    "    utterances = [utterance for utterance in chat.utterances()]\n",
    "    tokens = [(token, utterance.participant) for utterance in utterances for token in utterance.tokens]\n",
    "    words = [(token.word, participant) for (token, participant) in tokens]\n",
    "\n",
    "    if not full_transcript:\n",
    "      words = list(filter(lambda w: w[1] == 'PAR', words))\n",
    "    text = ''\n",
    "    for i, word_par in enumerate(words):\n",
    "      word = word_par[0]\n",
    "      par = word_par[1]\n",
    "      if word in ['POSTCLITIC']:\n",
    "        continue\n",
    "      if word in ['.', '?', '!']:\n",
    "        text += f'{word}\\n'\n",
    "      else:\n",
    "        if i == 0 or words[i-1][0] in ['.', '?', '!']:\n",
    "          if full_transcript:\n",
    "            text += f'{par}: '\n",
    "          text += word.capitalize()\n",
    "        else:\n",
    "          text += word\n",
    "        if i < len(words) - 1 and words[i+1][0] not in ['.', ',', '?', '!']:\n",
    "          text += ' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAR: This boy is about to fall off of the stool.\n",
      "PAR: The mother is washing dishes and the water's spilling over on the kitchen floor.\n",
      "PAR: The wind is blowing the curtains.\n",
      "PAR: The little girl is laughing at her brother who's taking a cookie out_of the cookie jar.\n",
      "PAR: Think that's it.\n",
      "INV: Okay.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(path_to_text(path.join(Paths.transcriptions, 'S160.cha'), full_transcript=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing S165...\n",
      "Processing S166...\n",
      "Processing S167...\n",
      "Processing S168...\n",
      "Processing S169...\n",
      "Processing S170...\n",
      "Processing S171...\n",
      "Processing S172...\n",
      "Processing S173...\n",
      "Processing S174...\n",
      "Processing S175...\n",
      "Processing S176...\n",
      "Processing S177...\n",
      "Processing S178...\n",
      "Processing S179...\n",
      "Processing S180...\n",
      "Processing S181...\n",
      "Processing S182...\n",
      "Processing S183...\n",
      "Processing S184...\n",
      "Processing S185...\n",
      "Processing S186...\n",
      "Processing S187...\n",
      "Processing S188...\n",
      "Processing S189...\n",
      "Processing S190...\n",
      "Processing S191...\n",
      "Processing S192...\n",
      "Processing S193...\n",
      "Processing S194...\n",
      "Processing S195...\n",
      "Processing S196...\n",
      "Processing S197...\n",
      "Processing S198...\n",
      "Processing S199...\n",
      "Processing S200...\n",
      "Processing S201...\n",
      "Processing S202...\n",
      "Processing S203...\n",
      "Processing S204...\n",
      "Processing S205...\n",
      "Processing S206...\n",
      "Processing S207...\n",
      "Processing S164...\n",
      "Processing S160...\n",
      "Processing S161...\n",
      "Processing S162...\n",
      "Processing S163...\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(Paths.transcriptions):\n",
    "  if file.endswith('.cha'):\n",
    "    ID = file.split('.')[0]\n",
    "    print(f'Processing {ID}...')\n",
    "\n",
    "    text_participants = path_to_text(path.join(Paths.transcriptions, file), full_transcript=False)\n",
    "    text_both = path_to_text(path.join(Paths.transcriptions, file), full_transcript=True)\n",
    "\n",
    "    if not os.path.exists(Paths.text_participants):\n",
    "      os.makedirs(Paths.text_participants)\n",
    "    with open(path.join(Paths.text_participants, f'{ID}.txt'), 'w') as f:\n",
    "      f.write(text_participants)\n",
    "\n",
    "    if not os.path.exists(Paths.text_both):\n",
    "      os.makedirs(Paths.text_both)\n",
    "    with open(path.join(Paths.text_both, f'{ID}.txt'), 'w') as f:\n",
    "      f.write(text_both)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
